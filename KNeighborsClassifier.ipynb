{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    \"\"\"\n",
    "    获取数据集\n",
    "    Returns:\n",
    "        df(DataFrame) 数据集\n",
    "    \"\"\"\n",
    "    column_names=['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n",
    "    df = pd.read_csv('Iris.txt', header=None, names=column_names)\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def minmaxscaler(df):\n",
    "    \"\"\"\n",
    "    线性归一化\n",
    "    Attributes:\n",
    "        df(DataFrame): 原始数据集\n",
    "    Returns:\n",
    "        new_df(DataFrame): 归一化处理后的数据集\n",
    "    \"\"\"\n",
    "    new_df = pd.DataFrame(index = df.index)\n",
    "    columns = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']\n",
    "    for col in columns:\n",
    "        data = df[col]\n",
    "        MAX = data.max()\n",
    "        MIN = data.min()\n",
    "        new_df[col] = ((data - MIN) / (MAX - MIN)).tolist()\n",
    "    new_df['Species'] = df['Species']\n",
    "    return new_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def train_test_split(dataset, proportion=0.7, random_seed=None):\n",
    "    \"\"\"\n",
    "    分割数据集\n",
    "    Attributes:\n",
    "        dataset(DataFrame): 数据集\n",
    "        proportion(Float): 训练集比例\n",
    "        random_seed: 随机数种子\n",
    "    Returns:\n",
    "        train_data(list): 训练集\n",
    "        test_data(lis): 测试集\n",
    "    \"\"\"\n",
    "    train_data = []\n",
    "    array = np.array(dataset)\n",
    "    test_data = array.tolist()\n",
    "    train_size = len(dataset) * proportion\n",
    "    random.seed(random_seed)\n",
    "    while len(train_data) < train_size:\n",
    "        train_data_idx = random.randrange(len(test_data))\n",
    "        train_data.append(test_data.pop(train_data_idx))\n",
    "#     return train_data, test_data\n",
    "    return pd.DataFrame(train_data, columns=dataset.columns), pd.DataFrame(test_data, columns=dataset.columns)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def kfold(dataset, k=10, random_seed=None):\n",
    "    \"\"\"\n",
    "    k折交叉验证, 每次分割都会打乱整个数据集, 等同于给定shuffle=True时的sklearn中的KFold\n",
    "    Attributes:\n",
    "        dataset(DataFrame): 数据集\n",
    "        k(int): 分割的块数\n",
    "        random_seed: 随机数种子\n",
    "    Returns:\n",
    "        train: k-1折数据形成训练集\n",
    "        test: 1折数据形成测试集\n",
    "    \"\"\"\n",
    "    train_data = []\n",
    "    array = np.array(dataset)\n",
    "    test_data = array.tolist()\n",
    "    train_size = int(len(dataset)/k)\n",
    "    random.seed(random_seed)\n",
    "    for i in range(k):\n",
    "        data_basket = []\n",
    "        if i!=k-1:\n",
    "            while len(data_basket) < train_size:\n",
    "                data_basket_idx = random.randrange(len(test_data))\n",
    "                data_basket.append(test_data.pop(data_basket_idx))\n",
    "        else:\n",
    "            data_basket = test_data\n",
    "        train_data.append(data_basket[:])\n",
    "#     return train_data[0:k-1], train_data[k-1]\n",
    "    train = train_data[0:k-1]\n",
    "    tmp = np.array(train)\n",
    "    tmp = tmp.reshape(tmp.shape[0]*tmp.shape[1], -1)\n",
    "    train = tmp\n",
    "    test = train_data[k-1]\n",
    "    train = pd.DataFrame(train, columns=dataset.columns)\n",
    "    test = pd.DataFrame(test, columns=dataset.columns)\n",
    "    columns = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']\n",
    "    train[columns] = train[columns].astype('float')\n",
    "    return train, test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def KNeighborsClassifier(X_test, X_train, y_train, k=5, distance_type='Euclidean'):\n",
    "    \"\"\"\n",
    "    kNN算法\n",
    "    Attributes：\n",
    "        X_test: 用于分类的输入向量\n",
    "        X_train: 训练样本集\n",
    "        y_train: 标签向量\n",
    "        k: 超参数,用于选择最近邻居的数目\n",
    "        distance_type: 超参数, 距离的计算方式--欧氏距离, 马尔科夫距离, 切比雪夫距离\n",
    "    Returns:\n",
    "        X_test: 所属的label\n",
    "    \"\"\"\n",
    "    if distance_type == 'Euclidean':\n",
    "        size = X_train.shape[0]\n",
    "        diff_mat = np.tile(X_test, (size, 1)) - X_train\n",
    "        sq_diff_mat = diff_mat**2\n",
    "        sq_distances = sq_diff_mat.sum(axis=1)\n",
    "        distances = sq_distances**0.5\n",
    "    elif distance_type == 'Manhattan':\n",
    "        size = X_train.shape[0]\n",
    "        diff_mat = np.tile(X_test, (size, 1)) - X_train\n",
    "        sq_diff_mat = abs(diff_mat)\n",
    "        sq_distances = sq_diff_mat.sum(axis=1)\n",
    "        distances = sq_distances\n",
    "    elif distance_type == 'Chebyshev':\n",
    "        size = X_train.shape[0]\n",
    "        diff_mat = np.tile(X_test, (size, 1)) - X_train\n",
    "        sq_diff_mat = abs(diff_mat)\n",
    "        sq_distances = np.amax(sq_diff_mat, axis=1)\n",
    "        distances = sq_distances\n",
    "    else:\n",
    "        return None\n",
    "    sorted_distances_indicies = distances.argsort()\n",
    "    class_count={}\n",
    "    for i in range(k):\n",
    "        vote_label = y_train[sorted_distances_indicies[i]]\n",
    "        class_count[vote_label] = class_count.get(vote_label, 0) + 1\n",
    "    sorted_class_count = sorted(class_count.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    y_score = {}\n",
    "    columns = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']\n",
    "    for i in columns:\n",
    "        if class_count.get(i) != None:\n",
    "            y_score[i] = (float(class_count.get(i)) / k)\n",
    "        else:\n",
    "            y_score[i] = 0.\n",
    "    return sorted_class_count[0][0], y_score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def train_model(train_data, test_data, KNN_k=5, distance_type='Euclidean'):\n",
    "    \"\"\"\n",
    "    训练模型\n",
    "    Attributes:\n",
    "        train_data(DataFrame): 训练集\n",
    "        test_data(DataFrame): 测试集\n",
    "        KNN_k(int): 超参数, 选择最近邻居的数目\n",
    "        distance_type: 超参数, 距离的计算方式--欧氏距离, 马尔科夫距离, 切比雪夫距离\n",
    "    Returns:\n",
    "        y_hat: 预测labels\n",
    "        y_test: 测试集labels\n",
    "        \"\"\"\n",
    "    X_train, y_train = train_data.iloc[:, 0:4], train_data.iloc[:, 4]\n",
    "    X_test, y_test = test_data.iloc[:, 0:4], test_data.iloc[:, 4]\n",
    "    y_hat = []\n",
    "    y_scores = []\n",
    "    for data in np.array(X_test).tolist():\n",
    "        y, y_score = KNeighborsClassifier(data, X_train, y_train, k=KNN_k, distance_type=distance_type)\n",
    "        y_hat.append(y)\n",
    "        y_scores.append(y_score)\n",
    "    y_test = np.array(y_test).tolist()\n",
    "    return y_hat, y_test, y_scores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def kfold_train(train_data, KNN_k, k=5, distance_type='Euclidean'):\n",
    "    \"\"\"\n",
    "    k折交叉验证进行模型调优\n",
    "    Attributes:\n",
    "        train_data(DataFrame): 训练集\n",
    "        KNN_k(int): 超参数, 选择最近邻居的数目\n",
    "        k(int): 交叉验证的折数\n",
    "        distance_type: 超参数, 距离的计算方式--欧氏距离, 马尔科夫距离, 切比雪夫距离\n",
    "    Returns:\n",
    "        accuracy: 准确度\n",
    "        \"\"\"\n",
    "    accuracy = 0.\n",
    "    for i in range(k):\n",
    "        train_data_kfold, test_data_kfold = kfold(dataset=train_data, k=k, random_seed=i*k)\n",
    "        y_hat, y_test, _ = train_model(train_data_kfold, test_data_kfold, KNN_k=KNN_k, distance_type=distance_type)\n",
    "        accuracy = accuracy + get_accuracy(y_hat, y_test)\n",
    "    accuracy = accuracy / float(k)\n",
    "    return accuracy\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def get_accuracy(y_hat, y_test):\n",
    "    correct = 0\n",
    "    for i in range(len(y_hat)):\n",
    "        if(y_hat[i] == y_test[i]):\n",
    "            correct = correct + 1\n",
    "    return correct / float(len(y_hat))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# 载入并归一化数据集\n",
    "dataset = load_dataset()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "SepalLength    0\nSepalWidth     0\nPetalLength    0\nPetalWidth     0\nSpecies        0\ndtype: int64"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看是否有缺失值\n",
    "dataset.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# 归一化数据集\n",
    "dataset = minmaxscaler(dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# 分割训练集与测试集\n",
    "train_data, test_data = train_test_split(dataset=dataset, proportion=0.8, random_seed=9)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "(7, 0.9833333333333332, 'Euclidean')"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模型调优,获取最佳的k值\n",
    "best_k = 0\n",
    "best_distance_type=\"\"\n",
    "best_accuracy = 0;\n",
    "for i in range(3, 18):\n",
    "    for distance_type in ['Euclidean', 'Manhattan', 'Chebyshev']:\n",
    "        accuracy = kfold_train(train_data, KNN_k=i, k=10, distance_type=distance_type)\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_k = i\n",
    "            best_distance_type = distance_type\n",
    "best_k, best_accuracy, best_distance_type"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# 重新训练模型并进行预测\n",
    "y_hat, y_test, y_scores = train_model(train_data, test_data, KNN_k=best_k, distance_type='Euclidean')\n",
    "accuracy = get_accuracy(y_hat, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.67%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {:.2%}\".format(accuracy))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
